{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "train_dir = 'Path/to/training_set'\n",
    "test_dir = 'Path/to/test_set'\n",
    "\n",
    "img_size = (150, 150)\n",
    "batch_size = 32\n",
    "# This sets the image size and batch size. all images will be resized to this ratio and the batch size sets the number of images that will be taken in for scanning\n",
    "\n",
    "epochs = 20"
    "# Then the number of epochs. The number of epochs can be varying depending on the dataset. for this specific code 15 to 20 is plenty enough.\n",
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "# This creates an image data generator with data augmentation for the training set\n",
    "\n",
   
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
     "# Image data generator for the testing set\n",
    
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "# Generator for the training set\n",
    "\n",
    
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "# Generator for the testing set\n",
    "\n",
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In this snippet we use the baisc Machine Learning knowlege to create a sequential model\n",
    "# This is how our program learns from the training set\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, a 3x3 kernel size, and ReLU activation\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another convolutional layer with 64 filters\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# ReLU (Rectified Linear Unit) activation is an activation function we use in machine learning.\n",
    "\n",
    "# Add another max pooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a third convolutional layer with 128 filters\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another max pooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output of the last convolutional layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected layer with 512 units and ReLU activation\n",
    
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add a dropout layer to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add an output layer with a sigmoid activation function\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and RMSprop optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Finally we train the model on the training set we provided aerlier. train generator was declared before\n",
    "model.fit(train_generator, epochs=epochs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# testing the model on the testing data set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)\n",
    "model.save('Path/to/save/weights/CatsAndDogsModel.h5')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
